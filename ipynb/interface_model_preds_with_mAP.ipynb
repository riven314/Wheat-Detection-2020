{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES\n",
    "1. need to filter out overlapping predicted bboxs before mAP metrics evaluation??\n",
    "    - YES! you need to do NMS to remove highly overlapping bboxs (see ```show_preds``` near ```process_output``` from fastai notebook [pascal.ipynb](https://github.com/fastai/course-v3/blob/master/nbs/dl2/pascal.ipynb))\n",
    "    - In summary the following procedures are needed: \n",
    "        - (i) process_output on predictions (for each sample) -- ```process_output```\n",
    "        - (ii) NMS on predicted bbox and scores -- ```nms```\n",
    "        - (iii) bbox from CTHW to TLBR format\n",
    "2. Following up on above, why ```unpad``` is not used (on target bbox and labels)??\n",
    "3. CTHW really refer H to Height, W to Width? (Why not CTWH)\n",
    "    - YES! CT = (y, x), HW = (height, width)\n",
    "4. TLBR is [x0, y0, x1, y1] OR [y0, x0, y1, x1]??\n",
    "    - [y0, x0, y1, x1]!! Top-Left-Bottom-Right\n",
    "5. TensorBBox after DataLoaders is in [x0, y0, x1, y1] OR [y0, x0, y1, x1]??\n",
    "    - it depends on the bbox format before transformation done by BBoxBlock, since my bbox output from ```get_annotations```, its bbox format is in [x0, y0, x1, y1]\n",
    "6. After ```unpad```, tgt_class is decremented by 1\n",
    "\n",
    "### Reference\n",
    "1. [RetinaNet demo -- pascal.ipynb](https://github.com/fastai/course-v3/blob/master/nbs/dl2/pascal.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "path = os.path.join(os.getcwd(), '..')\n",
    "sys.path.append(path)\n",
    "\n",
    "from pathlib import Path\n",
    "from pdb import set_trace\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from fastai2.vision.all import *\n",
    "\n",
    "from src.data.dblock import build_dblock\n",
    "from src.data.dls import build_dataloaders\n",
    "from src.model.model import get_retinanet, split_param_groups\n",
    "from src.metrics.loss import get_retinanet_loss\n",
    "from src.metrics.mAP import mAP\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Setup Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 24)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path('/userhome/34/h3509807/wheat-data')\n",
    "model_path = Path('/userhome/34/h3509807/Wheat-Detection-2020')\n",
    "\n",
    "dls = build_dataloaders(data_path, bs = 8, \n",
    "                        resize_sz = 256, norm = True, \n",
    "                        rand_seed = 144, test_mode = True)\n",
    "\n",
    "len(dls.train.items), len(dls.valid.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_retinanet()\n",
    "retinanet_loss = get_retinanet_loss(ratios = None, scales = None)\n",
    "learn = Learner(dls, model, path = model_path,\n",
    "                loss_func = retinanet_loss,\n",
    "                splitter = split_param_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('final_retinanet_learner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = learn.dls.one_batch()\n",
    "\n",
    "learn.model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = learn.model(b[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Interface Prediction with mAP Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics.utils import create_anchors, activ_to_bbox\n",
    "from src.metrics.utils import tlbr2cthw, cthw2tlbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_process_output(output, i, detect_thresh=0.25):\n",
    "    \"\"\" \n",
    "    Process `output[i]` and return the predicted bboxes above `detect_thresh`.\n",
    "    \n",
    "    :return:\n",
    "        bbox_pred : bbox in normalized cthw format\n",
    "        scores : confidence score after filtering\n",
    "        preds : class index for a predicted bbox\n",
    "    \"\"\"\n",
    "    clas_pred,bbox_pred,sizes = output[0][i], output[1][i], output[2]\n",
    "    \n",
    "    scales = [1, 2**(-1/3), 2**(-2/3)]\n",
    "    ratios = [1/2, 1, 2]\n",
    "    anchors = create_anchors(sizes, ratios, scales).to(clas_pred.device)\n",
    "    \n",
    "    bbox_pred = activ_to_bbox(bbox_pred, anchors)\n",
    "    clas_pred = torch.sigmoid(clas_pred)\n",
    "    \n",
    "    # argmax --> sigmoid(.) --> apply threshold\n",
    "    detect_mask = clas_pred.max(1)[0] > detect_thresh\n",
    "    bbox_pred, clas_pred = bbox_pred[detect_mask], clas_pred[detect_mask]\n",
    "    \n",
    "    # still expressed in cthw \n",
    "    bbox_pred = tlbr2cthw(torch.clamp(cthw2tlbr(bbox_pred), min=-1, max=1))    \n",
    "    scores, preds = clas_pred.max(1)\n",
    "    return bbox_pred, scores, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. From BBox Offset (bbox_pred) to BBox CTHW (p_bbox_pred)\n",
    "- bbox_pred is in batch\n",
    "- p_bbox_pred is in one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 46836, 4]),\n",
       " tensor([[ 0.3300,  0.3040, -0.6704, -1.0501],\n",
       "         [ 0.4119,  0.2938, -0.4941, -1.0316],\n",
       "         [ 0.3273,  0.3304, -0.3778, -0.9814]], device='cuda:0'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clas_pred, bbox_pred, sizes = preds\n",
    "\n",
    "bbox_pred.shape, bbox_pred[0, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([46456, 4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_bbox_pred, p_scores, p_preds = test_process_output(preds, 0, detect_thresh = 0.5)\n",
    "p_bbox_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9358, -0.8879,  0.1284,  0.2242],\n",
       "        [-0.9449, -0.9080,  0.1101,  0.1840],\n",
       "        [-0.9538, -0.9231,  0.0924,  0.1537]], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_bbox_pred[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Rescale BBox CTHW (p_bbox_pred) to BBox TLBR (tlbr_bbox_pred)\n",
    "- both p_bbox_pred, tlbr_bbox_pred is in one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics.utils import cthw2tlbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2500, -0.2500,  0.2500,  0.2500]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cthw_bbox = torch.as_tensor([[-0., -0., 0.5, 0.5]])\n",
    "cthw2tlbr(test_cthw_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([46456, 4]),\n",
       " tensor([[-1.0000, -1.0000, -0.8716, -0.7758],\n",
       "         [-1.0000, -1.0000, -0.8899, -0.8160],\n",
       "         [-1.0000, -1.0000, -0.9076, -0.8463]], device='cuda:0'))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlbr_bbox_pred = cthw2tlbr(p_bbox_pred)\n",
    "tlbr_bbox_pred.shape, tlbr_bbox_pred[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. BBox TLBR (tlbr_bbox_pred) to BBox Orig Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics.utils import decode_bboxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_bbox_pred = decode_bboxs(tlbr_bbox_pred, img_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([46456, 4]),\n",
       " tensor([[ 0.0000,  0.0000, 16.4398, 28.7014],\n",
       "         [ 0.0000,  0.0000, 14.0971, 23.5503],\n",
       "         [ 0.0000,  0.0000, 11.8308, 19.6754]], device='cuda:0'))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_bbox_pred.shape, scaled_bbox_pred[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Distribution of Confidence Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, figsize = (8, 5))\n",
    "\n",
    "hist_data = p_scores.flatten().cpu().numpy()\n",
    "ax.hist(hist_data, bins = 20)\n",
    "ax.set_title('Histogram of Confidence Score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Predicted Labels v.s. Target Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_bbox, tgt_clas = b[1][3], b[2][3]\n",
    "tgt_clas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Post-Processing on Target BBox and Target Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpad(tgt_bbox, tgt_clas, pad_idx=0):\n",
    "    \"\"\"\n",
    "    changes:\n",
    "    - all class labels decremented by 1 (padding label = -1)\n",
    "    - bbox change from TLBR to CTHW format\n",
    "    class labels for padding = -1\n",
    "    \"\"\"\n",
    "    i = torch.min(torch.nonzero(tgt_clas-pad_idx))\n",
    "    return tlbr2cthw(tgt_bbox[i:]), tgt_clas[i:]-1+pad_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40]),\n",
       " torch.Size([40, 4]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], device='cuda:0'),\n",
       " tensor([[-1.0000, -0.3242, -0.7871, -0.1328],\n",
       "         [-0.5391,  0.8613, -0.3457,  1.0000],\n",
       "         [-0.3047, -0.5098, -0.1367, -0.2441]], device='cuda:0'))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_bbox, tgt_clas = b[1][3], b[2][3]\n",
    "\n",
    "# target class labels from one sample\n",
    "tgt_clas.shape, tgt_bbox.shape, tgt_clas, tgt_bbox[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40]),\n",
       " torch.Size([40, 4]),\n",
       " tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0, -1, -1], device='cuda:0'),\n",
       " tensor([[-0.8936, -0.2285,  0.2129,  0.1914],\n",
       "         [-0.4424,  0.9307,  0.1934,  0.1387],\n",
       "         [-0.2207, -0.3770,  0.1680,  0.2656]], device='cuda:0'))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpad_tgt_bbox, unpad_tgt_clas = unpad(tgt_bbox, tgt_clas, pad_idx = 0)\n",
    "\n",
    "unpad_tgt_clas.shape, unpad_tgt_bbox.shape, unpad_tgt_clas, unpad_tgt_bbox[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpad_tgt_clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40]), torch.Size([40]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_clas.shape, unpad_tgt_clas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Sort scaled_bbox_pred in Descending Order of Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 46836, 1]), torch.Size([46456]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clas_pred.shape, p_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7086, 0.8301, 0.9394,  ..., 0.7744, 0.7749, 0.5193], device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000,  ..., 0.5032, 0.5029, 0.5020], device='cuda:0')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = torch.argsort(p_scores, dim = -1, descending = True)\n",
    "p_scores[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9501, -0.9500,  0.0999,  0.1000],\n",
       "        [-0.8591, -0.9520,  0.1771,  0.0895],\n",
       "        [-0.8921, -0.9519,  0.1753,  0.0896],\n",
       "        ...,\n",
       "        [-0.9590,  0.5784,  0.0821,  0.0560],\n",
       "        [-0.1472,  0.1293,  1.3922,  0.7115],\n",
       "        [-0.3592,  0.9627,  0.0559,  0.0746]], device='cuda:0')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_bbox_pred[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_preds[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
